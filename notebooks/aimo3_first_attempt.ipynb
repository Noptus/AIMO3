{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AIMO3 First Attempt (Composable + Kaggle-Automated)\n",
        "\n",
        "This notebook is a high-quality first baseline focused on:\n",
        "- `gpt-oss-120b` (or any OpenAI-compatible endpoint)\n",
        "- multi-attempt solving with weighted aggregation\n",
        "- tool-integrated reasoning via sandboxed Python code execution\n",
        "- automated Kaggle submission and status polling via API\n",
        "\n",
        "The code is shared with the package in `src/aimo3`, so improvements in one place are reusable everywhere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If running in a clean Kaggle/Colab runtime, uncomment:\n",
        "# !pip install -q kaggle pandas requests python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "ROOT = Path.cwd().resolve().parent if Path.cwd().name == \"notebooks\" else Path.cwd().resolve()\n",
        "SRC = ROOT / \"src\"\n",
        "if str(SRC) not in sys.path:\n",
        "    sys.path.insert(0, str(SRC))\n",
        "\n",
        "from aimo3.client import OpenAICompatChatClient\n",
        "from aimo3.kaggle_api import KaggleAutomation\n",
        "from aimo3.pipeline import run_inference, save_debug, save_submission\n",
        "from aimo3.solver import AIMO3Solver, SolverConfig\n",
        "\n",
        "print(\"Project root:\", ROOT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Runtime config\n",
        "AIMO_MODEL = os.getenv(\"AIMO_MODEL\", \"openai/gpt-oss-120b\")\n",
        "AIMO_BASE_URL = os.getenv(\"AIMO_BASE_URL\", \"http://127.0.0.1:8000/v1\")\n",
        "AIMO_API_KEY = os.getenv(\"AIMO_API_KEY\")\n",
        "\n",
        "solver_cfg = SolverConfig(\n",
        "    attempts=8,\n",
        "    temperatures=(0.15, 0.25, 0.35, 0.45),\n",
        "    max_tokens=1024,\n",
        "    min_consensus=3,\n",
        "    early_stop_attempt=4,\n",
        "    max_code_blocks_per_attempt=2,\n",
        "    default_answer=0,\n",
        ")\n",
        "\n",
        "client = OpenAICompatChatClient(\n",
        "    base_url=AIMO_BASE_URL,\n",
        "    model=AIMO_MODEL,\n",
        "    api_key=AIMO_API_KEY,\n",
        "    timeout_sec=180,\n",
        "    extra_body={\"top_p\": 0.95},\n",
        ")\n",
        "\n",
        "solver = AIMO3Solver(client, config=solver_cfg)\n",
        "print(\"Solver ready with model:\", AIMO_MODEL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Smoke test on a toy problem before full runs\n",
        "toy_problem = \"Compute 3^20 modulo 100000.\"\n",
        "result = solver.solve(problem_text=toy_problem, problem_id=\"toy-1\")\n",
        "print(result.debug_summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full batch inference (expects columns: id, problem)\n",
        "INPUT_CSV = ROOT / \"examples\" / \"sample_problems.csv\"  # replace with Kaggle test.csv path\n",
        "SUBMISSION_CSV = ROOT / \"artifacts\" / \"submission.csv\"\n",
        "DEBUG_JSON = ROOT / \"artifacts\" / \"debug_traces.json\"\n",
        "\n",
        "problems = pd.read_csv(INPUT_CSV)\n",
        "submission_df, debug_rows = run_inference(solver, problems, id_col=\"id\", problem_col=\"problem\", verbose=True)\n",
        "\n",
        "save_submission(submission_df, SUBMISSION_CSV)\n",
        "save_debug(debug_rows, DEBUG_JSON)\n",
        "\n",
        "print(\"Submission saved:\", SUBMISSION_CSV)\n",
        "print(\"Debug traces saved:\", DEBUG_JSON)\n",
        "submission_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kaggle API automation: submit and poll status\n",
        "# Requires KAGGLE_USERNAME + KAGGLE_KEY in environment (or KAGGLE_API_TOKEN=username:key)\n",
        "COMPETITION = \"ai-mathematical-olympiad-progress-prize-3\"\n",
        "MESSAGE = \"AIMO3 first composable baseline (gpt-oss-120b + sandbox)\"\n",
        "\n",
        "api = KaggleAutomation(COMPETITION)\n",
        "print(api.submit(SUBMISSION_CSV, message=MESSAGE))\n",
        "\n",
        "# Optional polling until scored\n",
        "final_state = api.wait_for_latest(poll_seconds=20, timeout_minutes=60)\n",
        "print(final_state)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}