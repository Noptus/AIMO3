# Final Run Report - 2026-02-11

## Scope

Executed final validation/inference runs to maximize completed coverage with current API constraints.

## Runs completed

### 1) Full reference sweep (breadth run)

- Command profile: `balanced`, model `openai/gpt-oss-20b`
- Key params: `attempts=1`, `max_tokens=256`, no verifier/selector/geometry recheck, timeout 60s
- Artifacts:
  - `artifacts/final_reference_full_fast/reference_predictions.csv`
  - `artifacts/final_reference_full_fast/reference_debug.json`
  - `artifacts/final_reference_full_fast/reference_summary.json`
- Result: **2 / 10 solved (20.0%)**

### 2) Final high-effort inference on test set

- Command profile: `aimo120b`, model `openai/gpt-oss-120b`
- Key params: attempts + repair + extractor + verifier + geometry recheck + selector enabled
- Artifacts:
  - `artifacts/submission_final_high_effort.csv`
  - `artifacts/debug_final_high_effort.json`
- Produced submission rows for all test ids.

### 3) Late-day robustness upgrade cycle

- Added contradiction stages and stronger arbitration:
  - `consistency_audit`
  - `adversarial_probe`
  - stage-diversity bonus in final aggregation
- Hardened parsing and extraction:
  - improved modulus extraction for LaTeX forms (`$10^{5}$`, `$5^7$`, `$99991$`)
  - tighter answer-line extraction heuristic
  - trimmed-context extractor/repair prompts to reduce truncation failures
- Added regression tests for new parser + solver behavior.
- Sanity check run:
  - `artifacts/reference_strategy_v4_quick`
  - result: `0/3` (under low budget / high truncation conditions; not representative of full 120B profile)

### 4) Kaggle notebook final submission attempt

- Pushed kernel: `raphaelcaillon/aimo3-progress-prize-3-working` version **5**
- Kernel status: **COMPLETE**
- Downloaded outputs:
  - `artifacts/kaggle_kernel_output_v5/submission.parquet`
  - `artifacts/kaggle_kernel_output_v5/submission.csv`
  - `artifacts/kaggle_kernel_output_v5/aimo3-progress-prize-3-working.log`
- Notebook metadata is configured for competition constraints:
  - internet disabled
  - writes required `submission.parquet`

## Operational notes

- Multiple deeper 120B reference benchmark attempts were started and intentionally stopped due high tail latency / poor completion reliability in this environment.
- A bounded final set of completed runs was prioritized to guarantee deliverables and artifacts.
- The main remaining reliability risk is long-output truncation before `FINAL_ANSWER` on some hosted runs; mitigation was added but still requires broader ablation.

## Recommended next run order

1. Run medium-depth full reference on 20B (`attempts=3`, verifier+selector on).
2. Run deep 120B on a smaller hard slice (`limit=3-4`) with checkpointing.
3. Promote best config to competition test inference and submit.
