<img src="https://r2cdn.perplexity.ai/pplx-full-logo-primary-dark%402x.png" style="height:64px;margin-right:32px"/>

# Let’s work together to solve: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3

First do a lot pf background research to guide our efforts

Now I have enough information to write a comprehensive research briefing. Let me compose the final answer.

# AIMO Progress Prize 3 — Comprehensive Research Briefing

## Competition Overview

The **AI Mathematical Olympiad Progress Prize 3 (AIMO3)** is a \$2.2M Kaggle competition launched by XTX Markets in November 2025, with the entry deadline on **April 8, 2026** and final submissions due **April 15, 2026**. It builds on AIMO1 (won by Project Numina, 29/50) and AIMO2 (won by NVIDIA NemoSkills, 34/50). The core objective: build an **open-source** model that can solve IMO-level math problems — closing the gap between open-weight and frontier commercial models.[^1][^2][^3]

The competition features **110 original problems** spanning algebra, combinatorics, geometry, and number theory, ranging from National Olympiad to full IMO difficulty. Problems are text-only in LaTeX, no diagrams. There are **50 public test** and **50 private test** problems, plus **10 reference problems** for development.[^4]

### Critical Rule Changes from AIMO2

| Feature | AIMO2 | AIMO3 |
| :-- | :-- | :-- |
| **Difficulty** | National Olympiad | National → IMO level |
| **Answer range** | 0–999 (mod 1000) | 0–99,999 (5-digit, explicit modulus per problem) |
| **GPU hardware** | 4× NVIDIA L4 (96 GB VRAM total) | **NVIDIA H100** (~2× compute) |
| **Winning score** | 34/50 | Target: high-40s |

The answer format change is significant — each problem now specifies its own modulus (e.g., $10^5$, 99991, or 57), and answers are 5-digit integers between 0 and 99,999. This makes random guessing virtually impossible (1/100,000 per problem vs 1/1,000 before).[^5][^4]

***

## The Gap We Need to Close

The 10-problem **AIMO3 Reference Bench** reveals the core challenge:[^4]


| Model | Score (out of 10) | Type |
| :-- | :--: | :-- |
| GPT-5 Pro / GPT-5.1 (high) | **10** | Commercial |
| GPT-5 (high) / Grok-4 / Gemini 2.5 Pro | **9** | Commercial |
| DeepSeek-v3.1-terminus (thinking, 671B) | **9** | Open-weight (very large) |
| **gpt-oss-120b** | **4** | Open-weight |
| Most other open-weight models | **0–4** | Open-weight |

Frontier commercial models solve 9–10/10 while most open-weight models can only handle the 4 easier problems (inherited from AIMO2 difficulty). The **one open-weight exception** is DeepSeek-v3.1-terminus at 671B parameters, which matched second-tier commercial models. This tells us the gap is real but closable with the right approach.

Currently on the public leaderboard (February 2026), top notebooks are scoring around **42/50**, with the leading approach using **gpt-oss-120b** (OpenAI's open-source 120B reasoning model).[^6][^7][^8][^9]

***

## Winning Approaches — Lessons from AIMO1 \& AIMO2

### AIMO2 Winner: NVIDIA NemoSkills (34/50)

The winning approach rested on three pillars:[^10][^11]

**1. Large-Scale Math Reasoning Dataset (OpenMathReasoning)**

- 540K unique high-quality math problems sourced from Art of Problem Solving (AoPS) forums
- 3.2M Chain-of-Thought (CoT) solutions generated by DeepSeek-R1 and QwQ-32B
- Rigorous decontamination against popular benchmarks
- Custom Comp-Math-24-25 validation benchmark (AIME + HMMT problems)

**2. Tool-Integrated Reasoning (TIR)**

- Models trained to interleave natural language reasoning with Python code execution
- Iterative pipeline: fine-tune → generate TIR solutions → quality filter → repeat
- Quality filtering ensured code blocks were "novel and significant" (not trivial)
- Controlled number of code execution blocks per generation
- Final dataset: 1.7M high-quality TIR solutions

**3. Generative Solution Selection (GenSelect)**

- Trained model to select the best solution from multiple candidates (better than majority voting)
- 566K training examples with summarized candidate solutions
- Model learned to compare and evaluate reasoning paths, not just final answers
- (Note: wasn't fully integrated into the final AIMO2 submission due to time constraints)

**Inference Optimizations:**

- TensorRT-LLM with FP8/INT8 quantization on L4 GPUs
- ReDrafter speculative decoding for faster generation
- FastAPI backend with per-problem time budgets (~350s + 200s buffer)
- Early stopping: if 4 of first 5 generations agree, take that answer
- Asynchronous generation to maximize GPU utilization
- Model merging (linear combination of CoT and TIR checkpoints)


### AIMO1 Winner: Project Numina

Key techniques that remain relevant:[^12][^13]

- **Self-Consistency TIR (SC-TIR)**: Generate 50–140 candidate solutions per problem with code execution
- **Custom scoring rule**: Weight code execution outputs (0.8 points) much higher than text-only answers (0.05 points)
- **Penalty heuristics**: Subtract confidence for "small number" answers and answers contained in the problem statement
- **Two prompt strategies**: 1) pure Chain-of-Thought, 2) Python/CAS-emphasizing — split 3:4 ratio
- **Parallelized code execution** in batches for throughput
- DeepSeekMath-7B fine-tuned with TRL + GPTQ quantization

***

## Model Landscape for AIMO3

Given the H100 GPU and the need for IMO-level reasoning, here are the key models:


| Model | Parameters | Key Strengths | AIMO3 Viability |
| :-- | :-- | :-- | :-- |
| **gpt-oss-120b** | 120B | Near o4-mini performance, variable reasoning effort, strong math/code | ★★★★★ — Current LB leader |
| **DeepSeek-v3.1/v3.2** | 671B MoE (37B active) | Thinking mode, IMO gold-level variants | ★★★★ — Fits on H100 with quantization |
| **QwQ-32B / Qwen3-32B** | 32B | Competitive with R1, fast inference | ★★★★ — Efficient, good for ensembles |
| **Fast-Math-Qwen3-14B** | 14B | 65% faster CoT, RL-tuned for math | ★★★ — Good for time-constrained generation |
| **OpenMath-Nemotron-32B** | 32B | SoTA open math reasoning, TIR-native | ★★★★ — Purpose-built for this |
| **Qwen3-235B-A22B** | 235B MoE (22B active) | Strong general reasoning, MoE efficiency | ★★★★ — May fit on H100 |

The **gpt-oss-120b** model is particularly interesting — it's OpenAI's open-source reasoning model that supports variable effort reasoning (low/medium/high) via system prompt, and performs near o4-mini levels on math benchmarks. Teams are already scoring 42/50 with it on the public leaderboard.[^9][^6]

***

## Strategic Recommendations for Our Approach

### Architecture: Multi-Model Ensemble with TIR

Based on the research, here's the recommended strategy stack:

**Tier 1 — Primary Solver: gpt-oss-120b**

- Use as the main reasoning engine with "high" reasoning mode
- Serve via vLLM or TensorRT-LLM with FP8 quantization on H100
- Generate multiple solution candidates per problem (target 8–16 per problem given time)
- Implement TIR: allow the model to write and execute Python code during reasoning

**Tier 2 — Fast Secondary Solver: QwQ-32B or Fast-Math-Qwen3-14B**

- Use for "easy" problems detected by early consensus, freeing time for harder ones
- Can generate more candidates faster due to smaller size
- Ensemble diversity improves overall accuracy

**Tier 3 — Solution Selection**

- Implement majority voting as baseline
- Upgrade to GenSelect-style verification if time permits (train a model to compare candidate solutions)
- Use code execution verification: only trust answers where code output matches the stated answer


### Key Technical Decisions

**1. Inference Engine**

- **vLLM** for flexibility and fast iteration during development
- **TensorRT-LLM** for final submission if maximum throughput is needed
- H100 enables FP8 natively — use it for ~2× throughput vs FP16

**2. Time Management**

- Budget ~6 minutes per problem average (50 problems × ~5 hours = 300 minutes)
- Implement dynamic time allocation: easy problems get less time, hard problems get more
- Early stopping: if N of first M generations agree, move on
- Track running time budget — never let a single hard problem consume all time

**3. Answer Extraction**

- Each AIMO3 problem specifies its own modulus — must parse this from the problem statement
- Implement robust regex/LLM-based modulus detection (can be 10^5, 99991, specific prime, etc.)
- Final answer extraction from `\boxed{}` or code output, then apply modulo

**4. Code Execution Integration**

- Sandboxed Python execution environment in the notebook
- Timeout per code block (e.g., 30 seconds)
- Parse code blocks from model output, execute, feed results back
- This is critical for computation-heavy problems (combinatorics, number theory with large numbers)

**5. Prompt Engineering**

- Two-prompt strategy: pure CoT + TIR (code-encouraging)
- System prompt should emphasize:
    - Step-by-step mathematical reasoning
    - Use Python/SymPy for verification and computation
    - Box the final integer answer
    - Specify the modulus parsing requirement


### Development Roadmap

| Phase | Timeline | Focus |
| :-- | :-- | :-- |
| **1. Baseline** | Week 1 | Get gpt-oss-120b running on H100 with vLLM, basic self-consistency pipeline, score reference problems |
| **2. TIR Integration** | Week 2–3 | Add code execution, implement sandbox, test on reference problems |
| **3. Time Management** | Week 3–4 | Dynamic time allocation, early stopping, GPU utilization optimization |
| **4. Ensemble \& Selection** | Week 4–6 | Add secondary model, implement voting/GenSelect, optimize answer extraction |
| **5. Fine-tuning** (optional) | Week 4–8 | Fine-tune QwQ-32B or Qwen3-14B on OpenMathReasoning + custom olympiad data |
| **6. Production Optimization** | Last 2 weeks | TensorRT-LLM, FP8 quantization, robustness testing, submission hardening |

### Validation Strategy

Crucially, with only 50 public test problems, overfitting to the public leaderboard is a real risk. Build internal validation using:

- **AIME 2024/2025** problems (30 problems per year)
- **HMMT 2024/2025** problems
- **IMO Shortlist** problems (those with integer answers)
- **OpenMathReasoning** hard subset
- The 10 reference problems (for smoke testing only — too small for real validation)


### Extra Prize Opportunities

AIMO3 offers several additional prizes worth pursuing:[^1]

- **Longest Leader Prize**: Maintain top leaderboard position for the longest cumulative time
- **Write-up Prizes**: Best technical explanation of approach
- **MathCorpus Prize**: Publish novel datasets
- **Hardest Problem Prize**: Best model on the least-solved problem

The Write-up and MathCorpus prizes are very achievable even without winning the main competition, and they provide excellent visibility.

***

## Immediate Next Steps

1. **Join the competition** on Kaggle and download the reference problems + submission demo notebook
2. **Set up local development** environment with vLLM + gpt-oss-120b (or start with QwQ-32B locally if GPU-constrained)
3. **Test the reference benchmark** — aim to solve all 10 reference problems to match DeepSeek-v3.1 performance
4. **Study the submission API** — understand the inference server pattern, time constraints, and answer extraction requirements
5. **Build the self-consistency pipeline** — generate multiple solutions, extract answers, vote

Want me to dive into any of these areas in detail — for example, setting up the inference pipeline, designing the TIR sandbox, or implementing the scoring/selection logic?
<span style="display:none">[^100][^101][^102][^103][^14][^15][^16][^17][^18][^19][^20][^21][^22][^23][^24][^25][^26][^27][^28][^29][^30][^31][^32][^33][^34][^35][^36][^37][^38][^39][^40][^41][^42][^43][^44][^45][^46][^47][^48][^49][^50][^51][^52][^53][^54][^55][^56][^57][^58][^59][^60][^61][^62][^63][^64][^65][^66][^67][^68][^69][^70][^71][^72][^73][^74][^75][^76][^77][^78][^79][^80][^81][^82][^83][^84][^85][^86][^87][^88][^89][^90][^91][^92][^93][^94][^95][^96][^97][^98][^99]</span>

<div align="center">⁂</div>

[^1]: https://aimoprize.com/updates/2025-11-19-third-progress-prize-launched

[^2]: https://aimoprize.com/updates/

[^3]: https://www.linkedin.com/posts/kaggle_ai-mathematical-olympiad-progress-prize-activity-7397295117558063106-heZs

[^4]: https://www.scribd.com/document/963275858/AIMO3-Reference-Problems

[^5]: https://www.kaggle.com/code/ryanholbrook/aimo-3-submission-demo

[^6]: https://www.kaggle.com/code/datasciencegrad/aimo-3-42-50-stable-lb-possible-43-luck/input

[^7]: https://www.kaggle.com/code/datasciencegrad/aimo-3-42-50-stable-lb-possible-43-luck?scriptVersionId=296084282

[^8]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion/665803

[^9]: https://arxiv.org/pdf/2508.10925.pdf

[^10]: https://www.themoonlight.io/zh/review/aimo-2-winning-solution-building-state-of-the-art-mathematical-reasoning-models-with-openmathreasoning-dataset

[^11]: https://beta.hyper.ai/en/papers/2504.16891

[^12]: https://www.youtube.com/watch?v=EdJXObMjalE

[^13]: https://huggingface.co/blog/winning-aimo-progress-prize

[^14]: https://www.youtube.com/watch?v=pE0ajV_08sY

[^15]: https://x.com/jiqizhixin/status/1991770622725353895

[^16]: https://www.youtube.com/watch?v=DUk1K0GVRQk

[^17]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion/672528

[^18]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion

[^19]: https://www.koreaherald.com/view.php?ud=20240402050752

[^20]: https://penelopefitdatascientist.substack.com/p/this-2m-data-competition-might-be

[^21]: https://github.com/jiayuzhao05/ai-mathematical-olympiad-progress-prize-2

[^22]: https://x.com/kaggle/status/1991530429955076427

[^23]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/overview/description

[^24]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3

[^25]: https://www.kaggle.com/docs/competitions

[^26]: https://www.reddit.com/r/kaggle/comments/17rise2/i_dont_understand_competition_submissions/

[^27]: https://www.kaggle.com/datasets/ritwikakancharla/aimo-3-benchmark

[^28]: https://www.reddit.com/r/kaggle/comments/ka19yy/kaggle_rules_pretrained_models/

[^29]: https://smo-testing.com/aimo/results/

[^30]: https://www.kaggle.com/code-competition-debugging

[^31]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion/639476

[^32]: https://www.kaggle.com/datasets/alejopaullier/aimo-external-dataset

[^33]: https://huggingface.co/datasets/John6666/knowledge_base_md_for_rag_1/blob/main/kaggle_20251121.md

[^34]: https://www.linkedin.com/posts/shan-wan-65015060_my-plan-for-tackling-the-aimo-prize-competition-activity-7398276147009966081-VL1L

[^35]: https://www.kaggle.com/competitions/map-charting-student-math-misunderstandings/discussion/591294

[^36]: https://www.imo-official.org/results.aspx

[^37]: https://www.bentoml.com/blog/the-complete-guide-to-deepseek-models-from-v3-to-r1-and-beyond

[^38]: https://stackoverflow.com/questions/62829611/how-to-activate-gpu-in-my-kaggle-notebook-it-uses-cpu-100-and-gpu-0-i-need-g

[^39]: https://aimo.world/history-2025

[^40]: https://www.kaggle.com/competitions/konwinski-prize/discussion/567003

[^41]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/rules

[^42]: https://www.reddit.com/r/LocalLLaMA/comments/1j4x8sq/new_qwq_is_beating_any_distil_deepseek_model_in/

[^43]: https://www.kaggle.com/questions-and-answers/231867

[^44]: https://www.reddit.com/r/DeepSeek/comments/1mnl2ou/good/

[^45]: https://www.kaggle.com/code/dschettler8845/aimo-let-s-learn-together/output?scriptVersionId=172871474

[^46]: https://www.youtube.com/watch?v=7rzpYw9URXU

[^47]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion/669690

[^48]: https://one-way-people.tistory.com/archive/20250503

[^49]: https://www.kaggle.com/code/masanakashima/aimo3-the-complete-inference-server-starter

[^50]: https://www.competehub.dev/en/competitions/kaggleai-mathematical-olympiad-progress-prize-3

[^51]: https://www.kaggle.com/code/piyushksinghh/aimo-progress-prize-3-submission/log

[^52]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion/662498

[^53]: https://blog.csdn.net/gitblog_00136/article/details/155007517

[^54]: https://www.reddit.com/r/LocalLLaMA/comments/1j9zqdr/why_deepseek_r1_is_still_a_reference_while_qwen/

[^55]: https://www.reddit.com/r/kaggle/comments/18yqgw8/what_do_you_do_when_your_model_requires_more_time/

[^56]: https://aimoprize.com/updates/2025-09-05-the-gap-is-shrinking

[^57]: https://www.kaggle.com/discussions/getting-started/586664

[^58]: https://www.kaggle.com/docs/efficient-gpu-usage

[^59]: https://arxiv.org/pdf/2504.16891.pdf

[^60]: https://massedcompute.com/faq-answers/?question=What+are+the+software+and+hardware+requirements+for+deploying+the+H100+GPU+in+a+cloud-based+AI+and+machine+learning+environment%3F

[^61]: https://www.linkedin.com/posts/sandi-bezjak-39bb12137_qwq-tiny-thinking-model-that-tops-deepseek-activity-7304045862958034944-JWe_

[^62]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion/669641

[^63]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion/651583

[^64]: https://www.kaggle.com/competitions/make-data-count-finding-data-references/discussion/585373

[^65]: https://huggingface.co/datasets/nvidia/OpenMathReasoning

[^66]: https://forums.fast.ai/t/it-takes-me-5-hours-to-run-one-epoch-with-a-kaggle-gpu-on-the-melanoma-classification-challenge/73593

[^67]: https://arxiv.org/html/2507.19849v1

[^68]: https://openreview.net/pdf/110e32186e208c949feb60e663a9f14c3e76244f.pdf

[^69]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-2

[^70]: https://www.ncbi.nlm.nih.gov/books/NBK566768/

[^71]: https://trustedmedia.aisingapore.org/competition/aisg/leaderboard/

[^72]: https://github.com/Frederisk/kaggle-action

[^73]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-2/discussion/540909

[^74]: https://www.kaggle.com/code

[^75]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/overview/timeline

[^76]: https://www.kaggle.com/code/mpwolke/gemma-what-s-the-remainder-h100-2m12s

[^77]: https://www.kaggle.com/code/bsmit1659/aimo-vllm-accelerated-tot-sc-deepseekmath/input

[^78]: https://www.reddit.com/r/kaggle/comments/1e64kej/same_notebook_creating_different_result/

[^79]: https://www.reddit.com/r/LocalLLaMA/comments/1kbzafi/qwen3_looks_like_the_best_open_source_model_rn/

[^80]: https://www.kaggle.com/code/ryanet/aimo-wizardmath-baseline-2-50/input

[^81]: https://o-mega.ai/articles/top-10-open-source-llms-the-deepseek-revolution-2026

[^82]: https://velog.io/@wjddms4299/Kaggle-AI-MO-Overview

[^83]: https://www.kaggle.com/code/rumankhan4/notebook51e4990a32

[^84]: https://huggingface.co/blog/daya-shankar/open-source-llms

[^85]: https://www.kaggle.com/code/mstsvgram/final-notebook

[^86]: https://whatllm.org/blog/best-open-source-models-january-2026

[^87]: https://blog.naver.com/fbfbf1/222442817246

[^88]: https://whatllm.org/blog/best-open-source-models-february-2026

[^89]: https://www.triangulai.com/en/projects/kaggle

[^90]: https://www.linkedin.com/pulse/great-llm-inference-showdown-tensorrt-llm-vs-vllm-vinay-jayanna-9o9pc

[^91]: https://github.com/ironbar/aimo

[^92]: https://www.lookeng.cn/2024/11/17/imo/kaggle-solution/

[^93]: https://www.whaleflux.com/blog/choosing-your-inference-engine-a-look-at-tensorrt-triton-and-vllm/

[^94]: https://compute.hivenet.com/post/vllm-vs-tgi-vs-tensorrt-llm-vs-ollama

[^95]: https://developer.nvidia.com/blog/how-to-streamline-complex-llm-workflows-using-nvidia-nemo-skills/

[^96]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion/672085

[^97]: https://github.com/project-numina/aimo-progress-prize/blob/main/kaggle-solution.ipynb

[^98]: https://www.nvidia.com/en-us/data-center/h100/

[^99]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion/635859

[^100]: https://www.reddit.com/r/LocalLLaMA/comments/1p73gjv/openaigptoss120b_scores_on_livecodebench/

[^101]: https://www.youtube.com/watch?v=-nNv0_ExvyU

[^102]: https://www.kaggle.com/code/shaocongxie/aimo3-h100-test

[^103]: https://www.kaggle.com/competitions/ai-mathematical-olympiad-progress-prize-3/discussion/671422

