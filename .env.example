# Inference endpoint (OpenAI-compatible, e.g. vLLM service)
AIMO_BASE_URL=http://127.0.0.1:8000/v1
AIMO_MODEL=openai/gpt-oss-120b
AIMO_API_KEY=

# Groq hosted inference (if set and AIMO_BASE_URL is unset, CLI auto-uses Groq endpoint)
GROQ_API_KEY=

# Kaggle API auth (preferred)
KAGGLE_USERNAME=
KAGGLE_KEY=

# Optional shorthand token format: username:key
# KAGGLE_API_TOKEN=
